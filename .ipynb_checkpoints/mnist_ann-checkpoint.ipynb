{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cab64f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Epoch: 1/100.. Training loss: 0.23975490259627502\n",
      "Epoch: 2/100.. Training loss: 0.09925811781063676\n",
      "Epoch: 3/100.. Training loss: 0.06605973129315923\n",
      "Epoch: 4/100.. Training loss: 0.04774344711055358\n",
      "Epoch: 5/100.. Training loss: 0.03512095049973577\n",
      "Epoch: 6/100.. Training loss: 0.02652588973424087\n",
      "Epoch: 7/100.. Training loss: 0.020171945853407185\n",
      "Epoch: 8/100.. Training loss: 0.015206235908220211\n",
      "Epoch: 9/100.. Training loss: 0.01175762940455849\n",
      "Epoch: 10/100.. Training loss: 0.009010360760540546\n",
      "Epoch: 11/100.. Training loss: 0.0071385049091186375\n",
      "Epoch: 12/100.. Training loss: 0.005817057266474391\n",
      "Epoch: 13/100.. Training loss: 0.004700807172122101\n",
      "Epoch: 14/100.. Training loss: 0.0040158031871037865\n",
      "Epoch: 15/100.. Training loss: 0.003336076434517357\n",
      "Epoch: 16/100.. Training loss: 0.0029662981903646143\n",
      "Epoch: 17/100.. Training loss: 0.0025848673289602933\n",
      "Epoch: 18/100.. Training loss: 0.0023238533300405833\n",
      "Epoch: 19/100.. Training loss: 0.0021050869803817475\n",
      "Epoch: 20/100.. Training loss: 0.00193657292938733\n",
      "Epoch: 21/100.. Training loss: 0.0017371153831195745\n",
      "Epoch: 22/100.. Training loss: 0.0016332476582184123\n",
      "Epoch: 23/100.. Training loss: 0.0015128894974729822\n",
      "Epoch: 24/100.. Training loss: 0.0014125395662830367\n",
      "Epoch: 25/100.. Training loss: 0.0013323751702914402\n",
      "Epoch: 26/100.. Training loss: 0.0012593338041726383\n",
      "Epoch: 27/100.. Training loss: 0.0011719301352806119\n",
      "Epoch: 28/100.. Training loss: 0.0011240872788087775\n",
      "Epoch: 29/100.. Training loss: 0.001060769050187082\n",
      "Epoch: 30/100.. Training loss: 0.0010098989486670082\n",
      "Epoch: 31/100.. Training loss: 0.0009696812484335775\n",
      "Epoch: 32/100.. Training loss: 0.0009238305717527206\n",
      "Epoch: 33/100.. Training loss: 0.00088328022385928\n",
      "Epoch: 34/100.. Training loss: 0.0008474833711962371\n",
      "Epoch: 35/100.. Training loss: 0.0008114712532010647\n",
      "Epoch: 36/100.. Training loss: 0.0007813558756775213\n",
      "Epoch: 37/100.. Training loss: 0.000754779111060634\n",
      "Epoch: 38/100.. Training loss: 0.0007254838827180114\n",
      "Epoch: 39/100.. Training loss: 0.0006999292522940474\n",
      "Epoch: 40/100.. Training loss: 0.0006770458909428271\n",
      "Epoch: 41/100.. Training loss: 0.0006538648717621981\n",
      "Epoch: 42/100.. Training loss: 0.0006344279686663261\n",
      "Epoch: 43/100.. Training loss: 0.0006127538844564697\n",
      "Epoch: 44/100.. Training loss: 0.0005951141833502333\n",
      "Epoch: 45/100.. Training loss: 0.0005769842747247215\n",
      "Epoch: 46/100.. Training loss: 0.0005605832591344855\n",
      "Epoch: 47/100.. Training loss: 0.0005477136228273594\n",
      "Epoch: 48/100.. Training loss: 0.0005300664136233536\n",
      "Epoch: 49/100.. Training loss: 0.0005167355830332478\n",
      "Epoch: 50/100.. Training loss: 0.0005036053707885003\n",
      "Epoch: 51/100.. Training loss: 0.0004917728171162405\n",
      "Epoch: 52/100.. Training loss: 0.0004787448763282252\n",
      "Epoch: 53/100.. Training loss: 0.00046733770812206783\n",
      "Epoch: 54/100.. Training loss: 0.0004558060386808696\n",
      "Epoch: 55/100.. Training loss: 0.0004451754640202125\n",
      "Epoch: 56/100.. Training loss: 0.0004355290106589867\n",
      "Epoch: 57/100.. Training loss: 0.0004263022787148657\n",
      "Epoch: 58/100.. Training loss: 0.0004151377849484561\n",
      "Epoch: 59/100.. Training loss: 0.0004073514341199674\n",
      "Epoch: 60/100.. Training loss: 0.000399281859734765\n",
      "Epoch: 61/100.. Training loss: 0.00039110614778668\n",
      "Epoch: 62/100.. Training loss: 0.00038299990484410955\n",
      "Epoch: 63/100.. Training loss: 0.0003734261135357277\n",
      "Epoch: 64/100.. Training loss: 0.0003672288231000493\n",
      "Epoch: 65/100.. Training loss: 0.0003608844009878036\n",
      "Epoch: 66/100.. Training loss: 0.00035392624389751293\n",
      "Epoch: 67/100.. Training loss: 0.000346620262915773\n",
      "Epoch: 68/100.. Training loss: 0.0003408319286737727\n",
      "Epoch: 69/100.. Training loss: 0.0003344550987070155\n",
      "Epoch: 70/100.. Training loss: 0.00032819784426052744\n",
      "Epoch: 71/100.. Training loss: 0.00032228574142560923\n",
      "Epoch: 72/100.. Training loss: 0.0003167736899387213\n",
      "Epoch: 73/100.. Training loss: 0.0003114352374125398\n",
      "Epoch: 74/100.. Training loss: 0.0003062145243042323\n",
      "Epoch: 75/100.. Training loss: 0.0003015336459919126\n",
      "Epoch: 76/100.. Training loss: 0.0002957006812891147\n",
      "Epoch: 77/100.. Training loss: 0.00029119482169953696\n",
      "Epoch: 78/100.. Training loss: 0.0002872466749656572\n",
      "Epoch: 79/100.. Training loss: 0.00028258023075310726\n",
      "Epoch: 80/100.. Training loss: 0.00027840721710405586\n",
      "Epoch: 81/100.. Training loss: 0.00027386589757449355\n",
      "Epoch: 82/100.. Training loss: 0.0002696831529611397\n",
      "Epoch: 83/100.. Training loss: 0.00026620750439027084\n",
      "Epoch: 84/100.. Training loss: 0.00026209592279028587\n",
      "Epoch: 85/100.. Training loss: 0.00025809768229658706\n",
      "Epoch: 86/100.. Training loss: 0.00025463038998768754\n",
      "Epoch: 87/100.. Training loss: 0.0002509072653916519\n",
      "Epoch: 88/100.. Training loss: 0.00024774474885792493\n",
      "Epoch: 89/100.. Training loss: 0.00024446225706815315\n",
      "Epoch: 90/100.. Training loss: 0.00024102088772254624\n",
      "Epoch: 91/100.. Training loss: 0.00023765357752624064\n",
      "Epoch: 92/100.. Training loss: 0.0002342811075877762\n",
      "Epoch: 93/100.. Training loss: 0.00023148941734925756\n",
      "Epoch: 94/100.. Training loss: 0.00022844828779986225\n",
      "Epoch: 95/100.. Training loss: 0.00022466700892418884\n",
      "Epoch: 96/100.. Training loss: 0.00022262246980959995\n",
      "Epoch: 97/100.. Training loss: 0.00021999444770572153\n",
      "Epoch: 98/100.. Training loss: 0.0002170546858345915\n",
      "Epoch: 99/100.. Training loss: 0.00021414130696657593\n",
      "Epoch: 100/100.. Training loss: 0.00021213746971322203\n"
     ]
    }
   ],
   "source": [
    "import mnist\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "try:\n",
    "    from sklearnex import patch_sklearn\n",
    "    patch_sklearn()\n",
    "except:\n",
    "    print(\"No scikit-learn-intelex found.  We go on with the classic implementation.\")\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Transformaciones para normalizar los datos\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Cargar los datos de entrenamiento y prueba\n",
    "train_data = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Crear dataloaders para iterar sobre los datos en lotes\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=True)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Capas de la red\n",
    "        self.fc1 = nn.Linear(28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Crear una instancia del modelo\n",
    "model = Net()\n",
    "\n",
    "# Definir una función de pérdida\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Definir un optimizador\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.05056733347837917)\n",
    "\n",
    "# Entrenar la red neuronal\n",
    "epochs = 100\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        # Limpiar los gradientes\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Calcular la salida del modelo\n",
    "        output = model(images)\n",
    "        \n",
    "        # Calcular la pérdida\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        # Calcular los gradientes\n",
    "        loss.backward()\n",
    "        \n",
    "        # Actualizar los pesos\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Epoch: {e+1}/{epochs}.. Training loss: {running_loss/len(train_loader)}\")\n",
    "        \n",
    "# Guardar el estado del modelo\n",
    "#torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "###########################################################\n",
    "\n",
    "# Crear una nueva instancia del modelo\n",
    "#model = Net()\n",
    "\n",
    "# Cargar el estado del modelo\n",
    "#model.load_state_dict(torch.load('model.pth'))\n",
    "\n",
    "# Evaluar el modelo\n",
    "#model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
